{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning using HyperDrive\n",
        "\n",
        "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "import csv\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pkg_resources\n",
        "\n",
        "import sklearn  \n",
        "\n",
        "import azureml.core\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.workspace import Workspace\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.core.dataset import Dataset\n",
        "from azureml.core.script_run_config import ScriptRunConfig\n",
        "\n",
        "from azureml.widgets import RunDetails\n",
        "from azureml.train.sklearn import SKLearn\n",
        "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive.policy import BanditPolicy\n",
        "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
        "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
        "from azureml.train.hyperdrive.parameter_expressions import uniform, choice\n",
        "import shutil\n",
        "\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SDK version: 1.26.0\n"
          ]
        }
      ],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1618549900253
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# azureml-core of version 1.0.72 or higher is required\n",
        "# azureml-dataprep[pandas] of version 1.1.34 or higher is required\n",
        "from azureml.core import Workspace, Dataset\n",
        "\n",
        "subscription_id = 'cdbe0b43-92a0-4715-838a-f2648cc7ad21'\n",
        "resource_group = 'aml-quickstarts-142814'\n",
        "workspace_name = 'quick-starts-ws-142814'\n",
        "\n",
        "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
        "\n",
        "dataset = Dataset.get_by_name(workspace, name='Banking_Transactions')\n",
        "transactions_df = dataset.to_pandas_dataframe()"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1618538961425
        },
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the fraction of data points that are fraudulent\n",
        "def fraudulent_percentage(transaction_df):\n",
        "    '''Calculate the fraction of all data points that have a 'Class' label of 1; fraudulent.\n",
        "       :param transaction_df: Dataframe of all transaction data points; has a column 'Class'\n",
        "       :return: A fractional percentage of fraudulent data points/all points\n",
        "    '''\n",
        "    # counts for all classes\n",
        "    counts = transactions_df['Class'].value_counts()\n",
        "    \n",
        "    # get fraudulent and valid cnts\n",
        "    fraud_cnts = counts[1]\n",
        "    valid_cnts = counts[0]\n",
        "    \n",
        "    # calculate percentage of fraudulent data\n",
        "    fraud_percentage = fraud_cnts/(fraud_cnts+valid_cnts)\n",
        "    \n",
        "    return fraud_percentage"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1618538986199
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# call the function to calculate the fraud percentage\n",
        "fraud_percentage = fraudulent_percentage(dataset)\n",
        "\n",
        "print('Fraudulent percentage = ', fraud_percentage)\n",
        "print('Total # of fraudulent pts: ', fraud_percentage*transactions_df.shape[0])\n",
        "print('Out of (total) pts: ', transactions_df.shape[0])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fraudulent percentage =  0.001727485630620034\n",
            "Total # of fraudulent pts:  492.0\n",
            "Out of (total) pts:  284807\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1618538994317
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the features dataframe\n",
        "x = transactions_df.iloc[:, :-1]\n",
        "# create the data label\n",
        "y = transactions_df['Class']\n",
        "\n",
        "# split data into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=50, shuffle=True)\n"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1618539019121
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "\n",
        "experiment_name = 'fraud_detection_hypervisor'\n",
        "\n",
        "experiment=Experiment(ws, experiment_name)\n",
        "\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
        "\n",
        "run = experiment.start_logging()\n",
        "print(experiment)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workspace name: quick-starts-ws-142814\n",
            "Azure region: southcentralus\n",
            "Subscription id: cdbe0b43-92a0-4715-838a-f2648cc7ad21\n",
            "Resource group: aml-quickstarts-142814\n",
            "Experiment(Name: fraud_detection_hypervisor,\n",
            "Workspace: quick-starts-ws-142814)\n"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1618539043534
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "# Create compute cluster\r\n",
        "# Choose a name for the computer cluster:\r\n",
        "amlcompute_cluster_name = \"compute-cluster\"\r\n",
        "\r\n",
        "# Check if the cluster already exists:\r\n",
        "try:\r\n",
        "    aml_compute = ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\r\n",
        "    print('The cluster already exists')\r\n",
        "except ComputeTargetException:\r\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2', max_nodes=4)\r\n",
        "    aml_compute = ComputeTarget.create(ws, amlcompute_cluster_name, compute_config)\r\n",
        "\r\n",
        "aml_compute.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating....\n",
            "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618539076245
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperdrive Configuration\n",
        "\n",
        "TODO: Explain the model you are using and the reason for chosing the different hyperparameters, termination policy and config settings."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598531923519
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# TODO: Create an early termination policy. This is not required if you are using Bayesian sampling.\n",
        "early_termination_policy = BanditPolicy(slack_factor = 0.1, evaluation_interval=1, delay_evaluation=5)\n",
        "\n",
        "#TODO: Create the different params that you will be using during training\n",
        "param_sampling = RandomParameterSampling({\n",
        "    \"--n_estimators\": choice(1, 2, 4, 8, 16, 32, 64, 100, 150, 200),\n",
        "    \"--max_depth\": choice(1, 2, 4, 8, 16, 32),\n",
        "    \"--min_samples_split\": choice(10, 20, 30, 40, 50, 60, 70, 80, 90, 100),\n",
        "    \"--max_features\": choice(1, 5, 10 , 15, 20, 25, 30)\n",
        "})\n",
        "\n",
        "#TODO: Create your estimator and hyperdrive config\n",
        "if \"training\" not in os.listdir():\n",
        "    os.mkdir(\"./training\")\n",
        "\n",
        "script_folder=\"./training\"\n",
        "\n",
        "# Create a copy the training script into the script_folder\n",
        "shutil.copy(\"./train.py\", script_folder)\n",
        "# Create a ScriptRunConfig estimator for use with train.py\n",
        "est = ScriptRunConfig(source_directory=\"./training\",\n",
        "        script=\"train.py\",\n",
        "        compute_target=aml_compute\n",
        ")\n",
        "\n",
        "hyperdrive_run_config = HyperDriveConfig(run_config=est,\n",
        "                                     hyperparameter_sampling=param_sampling,\n",
        "                                     policy=early_termination_policy,\n",
        "                                     primary_metric_name='AUC_weighted',\n",
        "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
        "                                     max_total_runs=20,\n",
        "                                     max_concurrent_runs=4)"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1618549259221
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit the experiment\n",
        "hyperdrive_run = experiment.submit(config=hyperdrive_run_config)\n"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1618549938827
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details\n",
        "\n",
        "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
        "\n",
        "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598544898497
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show run details with the widget\n",
        "RunDetails(hyperdrive_run).show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'â€¦",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb4b82d6f61a4937b2ed8f76e4fb7ddb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Running\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/HD_6b82e2bc-816c-46e3-a405-0cdc08ad7958?wsid=/subscriptions/cdbe0b43-92a0-4715-838a-f2648cc7ad21/resourcegroups/aml-quickstarts-142814/workspaces/quick-starts-ws-142814&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\", \"run_id\": \"HD_6b82e2bc-816c-46e3-a405-0cdc08ad7958\", \"run_properties\": {\"run_id\": \"HD_6b82e2bc-816c-46e3-a405-0cdc08ad7958\", \"created_utc\": \"2021-04-16T05:12:16.187306Z\", \"properties\": {\"primary_metric_config\": \"{\\\"name\\\": \\\"AUC_weighted\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"resume_from\": \"null\", \"runTemplate\": \"HyperDrive\", \"azureml.runsource\": \"hyperdrive\", \"platform\": \"AML\", \"ContentSnapshotId\": \"2111b576-e11a-409a-ab6e-fe07f062e42e\"}, \"tags\": {\"_aml_system_max_concurrent_jobs\": \"4\", \"max_concurrent_jobs\": \"4\", \"_aml_system_max_total_jobs\": \"20\", \"max_total_jobs\": \"20\", \"_aml_system_max_duration_minutes\": \"10080\", \"max_duration_minutes\": \"10080\", \"_aml_system_policy_config\": \"{\\\"name\\\": \\\"BANDIT\\\", \\\"properties\\\": {\\\"evaluation_interval\\\": 1, \\\"delay_evaluation\\\": 5, \\\"slack_factor\\\": 0.1}}\", \"policy_config\": \"{\\\"name\\\": \\\"BANDIT\\\", \\\"properties\\\": {\\\"evaluation_interval\\\": 1, \\\"delay_evaluation\\\": 5, \\\"slack_factor\\\": 0.1}}\", \"_aml_system_generator_config\": \"{\\\"name\\\": \\\"RANDOM\\\", \\\"parameter_space\\\": {\\\"--n_estimators\\\": [\\\"choice\\\", [[1, 2, 4, 8, 16, 32, 64, 100, 150, 200]]], \\\"--max_depth\\\": [\\\"choice\\\", [[1, 2, 4, 8, 16, 32]]], \\\"--min_samples_split\\\": [\\\"choice\\\", [[10, 20, 30, 40, 50, 60, 70, 80, 90, 100]]], \\\"--max_features\\\": [\\\"choice\\\", [[1, 5, 10, 15, 20, 25, 30]]]}}\", \"generator_config\": \"{\\\"name\\\": \\\"RANDOM\\\", \\\"parameter_space\\\": {\\\"--n_estimators\\\": [\\\"choice\\\", [[1, 2, 4, 8, 16, 32, 64, 100, 150, 200]]], \\\"--max_depth\\\": [\\\"choice\\\", [[1, 2, 4, 8, 16, 32]]], \\\"--min_samples_split\\\": [\\\"choice\\\", [[10, 20, 30, 40, 50, 60, 70, 80, 90, 100]]], \\\"--max_features\\\": [\\\"choice\\\", [[1, 5, 10, 15, 20, 25, 30]]]}}\", \"_aml_system_primary_metric_config\": \"{\\\"name\\\": \\\"AUC_weighted\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"primary_metric_config\": \"{\\\"name\\\": \\\"AUC_weighted\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"_aml_system_platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://southcentralus.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/cdbe0b43-92a0-4715-838a-f2648cc7ad21/resourceGroups/aml-quickstarts-142814/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-142814/experiments/fraud_detection_hypervisor\\\", \\\"SubscriptionId\\\": \\\"cdbe0b43-92a0-4715-838a-f2648cc7ad21\\\", \\\"ResourceGroupName\\\": \\\"aml-quickstarts-142814\\\", \\\"WorkspaceName\\\": \\\"quick-starts-ws-142814\\\", \\\"ExperimentName\\\": \\\"fraud_detection_hypervisor\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"train.py\\\", \\\"arguments\\\": [], \\\"target\\\": \\\"compute-cluster\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": 2592000, \\\"nodeCount\\\": 1, \\\"priority\\\": null, \\\"environment\\\": {\\\"name\\\": null, \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": false, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"name\\\": \\\"project_environment\\\", \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"azureml-defaults\\\"]}], \\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"]}}, \\\"docker\\\": {\\\"enabled\\\": false, \\\"baseImage\\\": \\\"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210301.v1\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": true}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"docker\\\": {\\\"useDocker\\\": false, \\\"sharedVolumes\\\": true, \\\"arguments\\\": [], \\\"shmSize\\\": \\\"2g\\\"}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"pytorch\\\": {\\\"communicationBackend\\\": \\\"nccl\\\", \\\"processCount\\\": null, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {}, \\\"data\\\": {}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": null}, \\\"command\\\": \\\"\\\"}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"2111b576-e11a-409a-ab6e-fe07f062e42e\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"660b3398-b80e-49d2-bc5b-ac1dc93b5254\\\", \\\"amlClientRequestId\\\": \\\"4ae15391-66aa-45ff-91ce-5c8a5d01918d\\\", \\\"amlClientSessionId\\\": \\\"1a536405-7163-4700-bb16-4fe570568ea2\\\", \\\"subscriptionId\\\": \\\"cdbe0b43-92a0-4715-838a-f2648cc7ad21\\\", \\\"estimator\\\": \\\"NoneType\\\", \\\"samplingMethod\\\": \\\"RANDOM\\\", \\\"terminationPolicy\\\": \\\"Bandit\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 20, \\\"maxConcurrentRuns\\\": 4, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://southcentralus.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/cdbe0b43-92a0-4715-838a-f2648cc7ad21/resourceGroups/aml-quickstarts-142814/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-142814/experiments/fraud_detection_hypervisor\\\", \\\"SubscriptionId\\\": \\\"cdbe0b43-92a0-4715-838a-f2648cc7ad21\\\", \\\"ResourceGroupName\\\": \\\"aml-quickstarts-142814\\\", \\\"WorkspaceName\\\": \\\"quick-starts-ws-142814\\\", \\\"ExperimentName\\\": \\\"fraud_detection_hypervisor\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"train.py\\\", \\\"arguments\\\": [], \\\"target\\\": \\\"compute-cluster\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": 2592000, \\\"nodeCount\\\": 1, \\\"priority\\\": null, \\\"environment\\\": {\\\"name\\\": null, \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": false, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"name\\\": \\\"project_environment\\\", \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"azureml-defaults\\\"]}], \\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"]}}, \\\"docker\\\": {\\\"enabled\\\": false, \\\"baseImage\\\": \\\"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210301.v1\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": true}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"docker\\\": {\\\"useDocker\\\": false, \\\"sharedVolumes\\\": true, \\\"arguments\\\": [], \\\"shmSize\\\": \\\"2g\\\"}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"pytorch\\\": {\\\"communicationBackend\\\": \\\"nccl\\\", \\\"processCount\\\": null, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {}, \\\"data\\\": {}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": null}, \\\"command\\\": \\\"\\\"}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"2111b576-e11a-409a-ab6e-fe07f062e42e\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"660b3398-b80e-49d2-bc5b-ac1dc93b5254\\\", \\\"amlClientRequestId\\\": \\\"4ae15391-66aa-45ff-91ce-5c8a5d01918d\\\", \\\"amlClientSessionId\\\": \\\"1a536405-7163-4700-bb16-4fe570568ea2\\\", \\\"subscriptionId\\\": \\\"cdbe0b43-92a0-4715-838a-f2648cc7ad21\\\", \\\"estimator\\\": \\\"NoneType\\\", \\\"samplingMethod\\\": \\\"RANDOM\\\", \\\"terminationPolicy\\\": \\\"Bandit\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 20, \\\"maxConcurrentRuns\\\": 4, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"_aml_system_resume_child_runs\": \"null\", \"resume_child_runs\": \"null\", \"_aml_system_all_jobs_generated\": \"false\", \"all_jobs_generated\": \"false\", \"_aml_system_cancellation_requested\": \"false\", \"cancellation_requested\": \"false\", \"_aml_system_progress_metadata_evaluation_timestamp\": \"\\\"2021-04-16T05:12:17.576343\\\"\", \"progress_metadata_evaluation_timestamp\": \"\\\"2021-04-16T05:12:17.576343\\\"\", \"_aml_system_progress_metadata_digest\": \"\\\"92c367b39cfcf4bbe0f1777f10b54c08522a9d99e17fc01b3d9d231172621cee\\\"\", \"progress_metadata_digest\": \"\\\"92c367b39cfcf4bbe0f1777f10b54c08522a9d99e17fc01b3d9d231172621cee\\\"\", \"_aml_system_progress_metadata_active_timestamp\": \"\\\"2021-04-16T05:12:17.576343\\\"\", \"progress_metadata_active_timestamp\": \"\\\"2021-04-16T05:12:17.576343\\\"\", \"_aml_system_optimizer_state_artifact\": \"null\", \"_aml_system_outdated_optimizer_state_artifacts\": \"\\\"[]\\\"\", \"_aml_system_HD_6b82e2bc-816c-46e3-a405-0cdc08ad7958_0\": \"{\\\"--max_depth\\\": 4, \\\"--max_features\\\": 30, \\\"--min_samples_split\\\": 60, \\\"--n_estimators\\\": 32}\", \"HD_6b82e2bc-816c-46e3-a405-0cdc08ad7958_0\": \"{\\\"--max_depth\\\": 4, \\\"--max_features\\\": 30, \\\"--min_samples_split\\\": 60, \\\"--n_estimators\\\": 32}\", \"_aml_system_HD_6b82e2bc-816c-46e3-a405-0cdc08ad7958_1\": \"{\\\"--max_depth\\\": 2, \\\"--max_features\\\": 10, \\\"--min_samples_split\\\": 30, \\\"--n_estimators\\\": 200}\", \"HD_6b82e2bc-816c-46e3-a405-0cdc08ad7958_1\": \"{\\\"--max_depth\\\": 2, \\\"--max_features\\\": 10, \\\"--min_samples_split\\\": 30, \\\"--n_estimators\\\": 200}\", \"_aml_system_HD_6b82e2bc-816c-46e3-a405-0cdc08ad7958_2\": \"{\\\"--max_depth\\\": 4, \\\"--max_features\\\": 5, \\\"--min_samples_split\\\": 20, \\\"--n_estimators\\\": 2}\", \"HD_6b82e2bc-816c-46e3-a405-0cdc08ad7958_2\": \"{\\\"--max_depth\\\": 4, \\\"--max_features\\\": 5, \\\"--min_samples_split\\\": 20, \\\"--n_estimators\\\": 2}\", \"_aml_system_HD_6b82e2bc-816c-46e3-a405-0cdc08ad7958_3\": \"{\\\"--max_depth\\\": 1, \\\"--max_features\\\": 5, \\\"--min_samples_split\\\": 60, \\\"--n_estimators\\\": 32}\", \"HD_6b82e2bc-816c-46e3-a405-0cdc08ad7958_3\": \"{\\\"--max_depth\\\": 1, \\\"--max_features\\\": 5, \\\"--min_samples_split\\\": 60, \\\"--n_estimators\\\": 32}\", \"_aml_system_environment_preparation_status\": \"PREPARING\", \"environment_preparation_status\": \"PREPARING\", \"_aml_system_prepare_run_id\": \"HD_6b82e2bc-816c-46e3-a405-0cdc08ad7958_preparation\", \"prepare_run_id\": \"HD_6b82e2bc-816c-46e3-a405-0cdc08ad7958_preparation\"}, \"end_time_utc\": null, \"status\": \"Running\", \"log_files\": {\"azureml-logs/hyperdrive.txt\": \"https://mlstrg142814.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_6b82e2bc-816c-46e3-a405-0cdc08ad7958/azureml-logs/hyperdrive.txt?sv=2019-02-02&sr=b&sig=xWheqHA2k%2FjHzck4awDEd9u9Vy%2FX0dG3kIoiD1NeIGo%3D&st=2021-04-16T05%3A02%3A23Z&se=2021-04-16T13%3A12%3A23Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/hyperdrive.txt\"]], \"run_duration\": \"0:00:07\", \"run_number\": \"39\", \"run_queued_details\": {\"status\": \"Running\", \"details\": null}, \"hyper_parameters\": {\"--n_estimators\": [\"choice\", [[1, 2, 4, 8, 16, 32, 64, 100, 150, 200]]], \"--max_depth\": [\"choice\", [[1, 2, 4, 8, 16, 32]]], \"--min_samples_split\": [\"choice\", [[10, 20, 30, 40, 50, 60, 70, 80, 90, 100]]], \"--max_features\": [\"choice\", [[1, 5, 10, 15, 20, 25, 30]]]}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"[2021-04-16T05:12:17.976981][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\\r\\n[2021-04-16T05:12:17.142611][API][INFO]Experiment created\\r\\n[2021-04-16T05:12:18.758199][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\\r\\n[2021-04-16T05:12:19.2826215Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.\\n\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.26.0\"}, \"loading\": false}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1618549943133
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyperdrive_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RunId: HD_5dea70ef-7054-455f-9909-744e02997b57\n",
            "Web View: https://ml.azure.com/runs/HD_5dea70ef-7054-455f-9909-744e02997b57?wsid=/subscriptions/cdbe0b43-92a0-4715-838a-f2648cc7ad21/resourcegroups/aml-quickstarts-142814/workspaces/quick-starts-ws-142814&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\n",
            "\n",
            "Streaming azureml-logs/hyperdrive.txt\n",
            "=====================================\n",
            "\n",
            "\"<START>[2021-04-16T05:01:10.133350][API][INFO]Experiment created<END>\\n\"\"<START>[2021-04-16T05:01:11.293998][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space<END>\\n\"\"<START>[2021-04-16T05:01:11.861597][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.<END>\\n\"<START>[2021-04-16T05:01:13.1184893Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.<END>\n",
            "\n",
            "Execution Summary\n",
            "=================\n",
            "RunId: HD_5dea70ef-7054-455f-9909-744e02997b57\n",
            "Web View: https://ml.azure.com/runs/HD_5dea70ef-7054-455f-9909-744e02997b57?wsid=/subscriptions/cdbe0b43-92a0-4715-838a-f2648cc7ad21/resourcegroups/aml-quickstarts-142814/workspaces/quick-starts-ws-142814&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 25,
          "data": {
            "text/plain": "{'runId': 'HD_5dea70ef-7054-455f-9909-744e02997b57',\n 'target': 'compute-cluster',\n 'status': 'Canceled',\n 'startTimeUtc': '2021-04-16T05:01:09.866476Z',\n 'endTimeUtc': '2021-04-16T05:09:47.429798Z',\n 'error': {'error': {'code': 'UserError',\n   'message': 'User errors were found in at least one of the child runs.',\n   'messageParameters': {},\n   'details': []},\n  'time': '0001-01-01T00:00:00.000Z'},\n 'properties': {'primary_metric_config': '{\"name\": \"AUC_weighted\", \"goal\": \"maximize\"}',\n  'resume_from': 'null',\n  'runTemplate': 'HyperDrive',\n  'azureml.runsource': 'hyperdrive',\n  'platform': 'AML',\n  'ContentSnapshotId': '2111b576-e11a-409a-ab6e-fe07f062e42e'},\n 'inputDatasets': [],\n 'outputDatasets': [],\n 'logFiles': {'azureml-logs/hyperdrive.txt': 'https://mlstrg142814.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_5dea70ef-7054-455f-9909-744e02997b57/azureml-logs/hyperdrive.txt?sv=2019-02-02&sr=b&sig=BmjZ4xiojtc5s1%2Bmo2eje7D6v6U7D%2FB38HYAsIbz%2B4Y%3D&st=2021-04-16T05%3A00%3A00Z&se=2021-04-16T13%3A10%3A00Z&sp=r'},\n 'submittedBy': 'ODL_User 142814'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1618549801420
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the hyperdrive experiments and display all the properties of the model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Get your best run and save the model from that run.\n",
        "\n",
        "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
        "print(best_run.get_details()['runDefinition']['arguments'])"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'get_details'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-c69578818970>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbest_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperdrive_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_run_by_primary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'runDefinition'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arguments'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_details'"
          ]
        }
      ],
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1598546650307
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
      ],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, send a request to the web service you deployed to test it."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, print the logs of the web service and delete the service"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}